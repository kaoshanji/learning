# 对 UNIX 网络编程 I/O 模型一点认识

人与人之间的对话、社交软件、电子邮件、手机电话/短信等等，都是一种通信方式，分别应用在不同的场景之下。

I/O 是人机及机器之间交互的过程，是用来解决通信的问题，有了通信就可以关联在一起，进而组成更大的组织。

Linux 的内核将所有外部设备都看做一个文件来操作，对一个文件的读写操作会调用内核提供的系统命令，返回一个 file descriptor(fc，文件描述符)。而对一个 socket 的读写也会有相应的描述符，称为 socketfd(socket描述符)，描述符就是一个数字，它指向内核中的一个结构体(文件路径，数据区等一些属性).

UNIX 网络编程对I/O模型的分类：同步阻塞I/O、同步非阻塞I/O、多路复用I/O、信号驱动I/O、异步I/O等5种。

CPU访问内存的速度远远高于外部设备，是先把外部设备的数据读到内存再进行处理，这需要一点时间，在这个过程中CPU怎么办?

网络I/O通信过程，会涉及两个对象：调用这个I/O操作的用户线程，另一个是操作系统内核。

进程空间分为用户空间和内核空间，用户线程不能直接访问内核空间。

- 用户线程发起I/O操作后，网络数据读取有两个步骤： 网卡数据 --> 内核空间 --> 用户空间，期间用户线程等待，内核忙活
  - 用户线程等待内核将数据从网卡`拷贝`到`内核空间`
  - 内核将数据从内核空间`拷贝`到`用户空间`

各种I/O模型的区别就是，实现这两步的过程不一样：用户线程、CPU、内核拷贝数据到用户空间

- [I/O 系统 Java实现](https://github.com/kaoshanji/learning/blob/master/server/lang/l001/j001/j104/bbb/README.md)
- 观察各种模式的示意图，右边关于内核操作的过程一直都是两个阶段没有变化，变化的是左边应用程序请求交互过程

##  同步阻塞 I/O

[示意图](https://www.processon.com/view/link/5e4fdf5ee4b0cc44b5a54d1d)
  
用户线程发起read调用后`阻塞`，让出CPU，内核拷贝数据到用户空间再把用户线程唤醒

在用户进程空间中调用 recvfrom ，其系统调用直到数据包(网络数据)到达且被`复制`到应用进程的缓冲区或者发生错误时才会返回，在此期间一直会等待，进程在从调用 recvfrom 开始到他返回的整段时间内都是被阻塞的，即 阻塞I/O模型。

##  非阻塞I /O

[示意图](https://www.processon.com/view/link/5e500511e4b0362764fbd099)

网卡数据没有到内核空间之前，用户线程不断发起read调用，只是返回失败；数据到达内核空间之后，用户线程就`阻塞`，等内核拷贝数据到用户空间再唤醒

recvfrom 从应用层到内核的时候，如果该缓冲区没有数据的话，就直接返回一个 EWOULDBLOCK 错误，一般都对非阻塞 I/O 模型进行轮询检查这个状态，看内核是不是有数据到来。


##  I/O 复用模型

[示意图](https://www.processon.com/view/link/5e50053be4b0cb56daa1d4ca)

用户线程把读取操作分成两步：先发起 select 调用，问下内核数据准备好了没?当准备好了，就发起 read 调用

在等待数据从内核空间到用户空间期间，线程是`阻塞`的，准备好了再唤醒

一次 select 调用可以向内核查询多个数据通道的状态，就叫多路复用了。

Linux 提供 select/poll，进程通过一个或多个 fd 传递给 select/poll 系统调用，阻塞在 select 操作上，这样 select/poll 可以侦测多个 fd 是否处于就绪状态。

select/poll 是顺序扫描 fd 是否就绪，而且支持的 fd 数量有限，因此受到一些制约。

Linux 还提供了一个 epoll 系统调用， epoll 使用基于事件驱动方式代替顺序扫描，性能更高，当有 fd 就绪时，立即回调函数 rollback。

### epoll 改进

- 支持一个进程打开的 socket 描述符(fd)不受限制(仅受限于操作系统的最大文件句柄数)

select 最大的缺陷是单个进程所打开的 fd 是有一定限制的，由 FD_SETSIZE 设置，默认值是 1024，不能应对上万个TCP连接。

epoll 就没有这个限制，所支持的 fd 上限是操作系统的最大文件句柄数，这个数字远远大于 1024，主要受系统的内存影响，例如 1GB 内存的机器大约是 100000 个句柄左右。

- I/O 效率不会随着 fd 数目的增加而线性下降

当有一个很大的 socket 集合，但是一时刻只有少量socket是 "活跃"的，也还是会线性扫描全部的集合，效率就下降了。

epoll 是只会对 "活跃"的socket进行操作--因为在内核实现中 epoll 是根据每个 fd 上面的 callback 函数实现，也只有"活跃"的socket才会主动去调用 callback 函数。

活跃的socket会自己暴露出来，不用去主动在全部里寻找。

如果所有的 socket 都处于活跃态，例如一个高速 LAN 环境，两种方式效率就相当。

- 使用 mmap 加速内核与用户空间的消息传递

epoll 可以实现避免必须的那次拷贝，通过内核和用户空间 mmap 同一块内存实现。

虚拟内存地址映射：用户空间持有的虚拟地址和内核空间持有的虚拟地址映射到同一块内存。

##  信号驱动I/O模型

[示意图](https://www.processon.com/view/link/5e50056be4b07f2b831d62cc)

首先开启套接口信号驱动 I/O 功能，并通过系统调用 sigaction 执行一个信号处理函数(此系统调用立即返回，进程继续工作，他是非阻塞的)。当数据准备就绪时，就为该进程生成一个 SIGIO 信号，通过信号回调通知应用程序调用 recvfrom 来读取数据，并通知主循环函数处理数据。

##  异步I/O

[示意图](https://www.processon.com/view/link/5e50058ee4b0cc44b5a56ffe)

用户线程发起 read 调用的同时注册一个回调函数就返回，内核把数据准备好了就调用指定的函数，这个过程中用户线程没有阻塞。

告知内核启动某个操作，并让内核在整个操作完成后(包括将数据从内核复制到用户自己的缓冲区)通知过来。

与信号驱动模型的主要区别是：信号驱动I/O由内核通知何时可以开始一个I/O操作，异步I/O模型由内核通知I/O操作何时已经完成。

##  术语

`阻塞和非阻塞`，是指应用程序在发起I/O操作时，是立即返回还是等待

`同步和异步`，是指应用程序在与内核通信时，数据从内核空间到用户空间的拷贝，是由内核主动发起还是应用程序来`触发`，同步就是应用程序触发，异步是内核触发

- 参考
  - 《Netty权威指南》 李林锋：第1章 Java 的I/O演进之路
  - [14 | NioEndpoint组件：Tomcat如何实现非阻塞I/O？](https://time.geekbang.org/column/article/100307)

  ----